{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Question_Answering_Bert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMbpSuvoNjRCMN9j/oRz2dY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lazycoderr/NLP/blob/main/Question_Answering_Bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpFdm3GnK65k"
      },
      "source": [
        "# using the transformers libraries from Huggingface\n",
        "!pip install --quiet transformers"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dP0nVBjtL61E"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETu15I4HLGWW"
      },
      "source": [
        "\"\"\"\n",
        "Using the bert large model.\n",
        "layers = 24\n",
        "embedding size = 1024\n",
        "Parameters = 340M\n",
        "Size = 1.34 GB\n",
        "\"\"\"\n",
        "from transformers import BertForQuestionAnswering\n",
        "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMU6wl-lMAF8"
      },
      "source": [
        "# Loading the tokenizer\n",
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JgzAv_nd8Bm"
      },
      "source": [
        "def ask_question(question,answer_text):\n",
        "  input_ids = tokenizer.encode(question,answer_text)\n",
        "  sep_index = input_ids.index(tokenizer.sep_token_id)\n",
        "  ques = sep_index+1\n",
        "  ans_seg = len(input_ids) - num_seg_a\n",
        "  segment_ids = [0]*ques + [1]*ans_seg\n",
        "  assert len(segment_ids) == len(input_ids)\n",
        "  outputs = model(torch.tensor([input_ids]),\n",
        "               token_type_ids = torch.tensor([segment_ids]),\n",
        "               return_dict = True)\n",
        "  start_scores = outputs.start_logits\n",
        "  end_scores = outputs.end_logits\n",
        "  answer_start = torch.argmax(start_scores)\n",
        "  answer_end = torch.argmax(end_scores)\n",
        "  tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "  answer = ' '.join(tokens[answer_start:answer_end+1])\n",
        "  return answer\n"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyQw9qFMgC4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de69648d-79b5-4dde-a8da-3eb1134cc96d"
      },
      "source": [
        "answer_text = input(\"Enter answer Text\")"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter answer TextSince we fetch amount for TIV feild from Attachments, email body and last but not the least from the subject line. So we check using the reg ex for the all the three sources in the respective orders.  If we get the value for the TIV then we give priority to attachments followed by email body and last to the subject line. Suppose the TIV gross amount is 7000. If is not able to detect then we use BERT Question approach method.Since we fetch amount for TIV feild from Attachments, email body and last but not the least from the subject line. So we check using the reg ex for the all the three sources in the respective orders.  If we get the value for the TIV then we give priority to attachments followed by email body and last to the subject line. Suppose the TIV gross amount is 7000. If is not able to detect then we use BERT Question approach method. Boba is the largest location and the gross amount is 98000.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6A6D3Qua1Eo",
        "outputId": "2ee9ce4f-0efe-4099-f5a6-46c2895485de"
      },
      "source": [
        "question = input(\"Ask a Question\")\n"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ask a Questionfrom where we fetch amount for TIV?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBbLCZ5SgIro",
        "outputId": "ec31e6b1-f160-45e4-d06b-99c04e786aca"
      },
      "source": [
        "print(ask_question(question,answer_text))"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "attachment ##s , email body and last but not the least from the subject line\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXC-tCApmBmv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}